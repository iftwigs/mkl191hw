{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from deeppavlov import configs, build_model, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('pristavki.csv', header=None, names=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with configs.ner.ner_ontonotes_bert_mult.open(encoding='utf8') as f:\n",
    "    ner_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_config['dataset_reader']['data_path'] = './tr-t'  \n",
    "ner_config['metadata']['variables']['NER_PATH'] = './tr-t'\n",
    "ner_config['metadata']['download'] = [ner_config['metadata']['download'][-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-14 15:25:35.804 WARNING in 'deeppavlov.dataset_readers.conll2003_reader'['conll2003_reader'] at line 96: Skip '-0\\n', splitted as ['-0']\n",
      "2020-01-14 15:25:35.813 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 68: NNTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/core/trainers/nn_trainer.py:149: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2020-01-14 15:25:40.493 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /Users/macbookpro/Downloads/tr-t/tag.dict]\n",
      "2020-01-14 15:25:40.499 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /Users/macbookpro/Downloads/tr-t/tag.dict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-14 15:26:06.138 INFO in 'deeppavlov.models.bert.bert_sequence_tagger'['bert_sequence_tagger'] at line 251: [initializing model with Bert from /Users/macbookpro/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/models/bert/bert_sequence_tagger.py:255: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /Users/macbookpro/.deeppavlov/downloads/bert_models/multi_cased_L-12_H-768_A-12/bert_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-14 15:26:13.225 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 83 tokens with 8 phrases; found: 1 phrases; correct: 0.\n",
      "\n",
      "precision:  0.00%; recall:  0.00%; FB1:  0.00\n",
      "\n",
      "\t: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\t00р: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\t0р/: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tGAME: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
      "\n",
      "\n",
      "2020-01-14 15:26:13.227 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 5, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:00:03\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-14 15:30:19.706 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 288 tokens with 56 phrases; found: 56 phrases; correct: 0.\n",
      "\n",
      "precision:  96.43%; recall:  96.43%; FB1:  96.43\n",
      "\n",
      "\t: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\t00р: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\t0р/: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tGAME: precision:  96.43%; recall:  96.43%; F1:  96.43 56\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/macbookpro/miniconda3/lib/python3.7/site-packages/deeppavlov/core/trainers/nn_trainer.py:249: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "{\"train\": {\"eval_examples_count\": 15, \"metrics\": {\"ner_f1\": 96.4286, \"ner_token_f1\": 98.9583}, \"time_spent\": \"0:04:09\", \"epochs_done\": 19, \"batches_seen\": 20, \"train_examples_seen\": 300, \"head_learning_rate\": 0.009999999776482582, \"bert_learning_rate\": 1.9999999552965164e-05, \"loss\": 14.365330392122269}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-14 15:30:20.393 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 83 tokens with 8 phrases; found: 14 phrases; correct: 0.\n",
      "\n",
      "precision:  50.00%; recall:  87.50%; FB1:  63.64\n",
      "\n",
      "\t: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tGAME: precision:  50.00%; recall:  87.50%; F1:  63.64 14\n",
      "\n",
      "\n",
      "2020-01-14 15:30:20.398 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 63.6364\n",
      "2020-01-14 15:30:20.399 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2020-01-14 15:30:20.476 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /Users/macbookpro/Downloads/tr-t/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 5, \"metrics\": {\"ner_f1\": 63.6364, \"ner_token_f1\": 92.7711}, \"time_spent\": \"0:04:10\", \"epochs_done\": 19, \"batches_seen\": 20, \"train_examples_seen\": 300, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-14 15:33:05.173 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /Users/macbookpro/Downloads/tr-t/tag.dict]\n",
      "2020-01-14 15:33:32.962 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /Users/macbookpro/Downloads/tr-t/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/macbookpro/Downloads/tr-t/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-14 15:33:42.134 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 83 tokens with 8 phrases; found: 14 phrases; correct: 0.\n",
      "\n",
      "precision:  50.00%; recall:  87.50%; FB1:  63.64\n",
      "\n",
      "\t: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tGAME: precision:  50.00%; recall:  87.50%; F1:  63.64 14\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 5, \"metrics\": {\"ner_f1\": 63.6364, \"ner_token_f1\": 92.7711}, \"time_spent\": \"0:00:03\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-14 15:33:42.633 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 394: processed 80 tokens with 18 phrases; found: 18 phrases; correct: 0.\n",
      "\n",
      "precision:  66.67%; recall:  66.67%; FB1:  66.67\n",
      "\n",
      "\t: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
      "\n",
      "\tGAME: precision:  66.67%; recall:  66.67%; F1:  66.67 18\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"test\": {\"eval_examples_count\": 5, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 91.25}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-14 15:33:43.403 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /Users/macbookpro/Downloads/tr-t/tag.dict]\n",
      "2020-01-14 15:34:08.119 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /Users/macbookpro/Downloads/tr-t/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/macbookpro/Downloads/tr-t/model\n"
     ]
    }
   ],
   "source": [
    "ner_model = train_model(ner_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['1',\n",
       "   'assassins',\n",
       "   'creed',\n",
       "   'синдикат',\n",
       "   ',',\n",
       "   '2',\n",
       "   'unit',\n",
       "   '13',\n",
       "   ',',\n",
       "   '3',\n",
       "   'little',\n",
       "   'big',\n",
       "   'planet']],\n",
       " [['B-GAME',\n",
       "   'B-GAME',\n",
       "   'I-GAME',\n",
       "   'I-GAME',\n",
       "   '0',\n",
       "   'B-GAME',\n",
       "   'B-GAME',\n",
       "   'I-GAME',\n",
       "   '0',\n",
       "   '0',\n",
       "   'B-GAME',\n",
       "   'I-GAME',\n",
       "   'I-GAME']]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['1 assassins creed синдикат, 2 unit 13, 3 little big planet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "marked = []\n",
    "\n",
    "for text in data.text.values[:1000]:\n",
    "    if len(text.split()) > 100:\n",
    "        continue\n",
    "    pred = ner_model([text])\n",
    "    sent, tags = pred[0][0], pred[1][0]\n",
    "\n",
    "    if len(set(tags[0])) > 1:\n",
    "        marked.append(list(zip(sent,tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Sony', 'B-GAME'),\n",
       "  ('PS3', 'I-GAME'),\n",
       "  ('в', '0'),\n",
       "  ('отличном', '0'),\n",
       "  ('состоянии', '0'),\n",
       "  (',', '0'),\n",
       "  ('продаю', '0'),\n",
       "  ('за', '0'),\n",
       "  ('ненадобностью', '0'),\n",
       "  (',', '0'),\n",
       "  ('память', '0'),\n",
       "  ('12gb', 'B-GAME'),\n",
       "  ('-', '0'),\n",
       "  ('встроенные', '0'),\n",
       "  ('+', '0'),\n",
       "  ('жесткий', '0'),\n",
       "  ('диск', '0'),\n",
       "  ('на', '0'),\n",
       "  ('160gb', 'B-GAME'),\n",
       "  (',', '0'),\n",
       "  ('в', '0'),\n",
       "  ('комплект', '0'),\n",
       "  ('входит', '0'),\n",
       "  ('два', '0'),\n",
       "  ('джойстика', '0'),\n",
       "  ('(', '0'),\n",
       "  ('состояние', '0'),\n",
       "  ('новых', '0'),\n",
       "  (',', '0'),\n",
       "  ('не', '0'),\n",
       "  ('залипают', '0'),\n",
       "  (',', '0'),\n",
       "  ('не', '0'),\n",
       "  ('тупят', '0'),\n",
       "  (',', '0'),\n",
       "  ('играли', '0'),\n",
       "  ('мало', '0'),\n",
       "  (')', '0'),\n",
       "  (',', '0'),\n",
       "  ('игра', '0'),\n",
       "  ('FIFA', 'B-GAME'),\n",
       "  ('2014', 'I-GAME'),\n",
       "  (',', '0'),\n",
       "  ('кабель', '0'),\n",
       "  ('hdmi', 'B-GAME'),\n",
       "  (',', '0'),\n",
       "  ('коробка', '0'),\n",
       "  ('.', '0')],\n",
       " [('Игра', 'B-GAME'),\n",
       "  ('праздник', 'I-GAME'),\n",
       "  ('спорта', 'I-GAME'),\n",
       "  ('/', '0'),\n",
       "  ('\\n', '0'),\n",
       "  ('/', '0'),\n",
       "  ('\\n', '0'),\n",
       "  ('ПС3', 'B-GAME'),\n",
       "  ('Мув', 'B-GAME'),\n",
       "  ('/', '0'),\n",
       "  ('\\n', '0'),\n",
       "  ('/', '0'),\n",
       "  ('\\n', '0'),\n",
       "  ('Камера', 'B-GAME')],\n",
       " [('Battlefield', 'B-GAME'),\n",
       "  ('4', 'I-GAME'),\n",
       "  (',', '0'),\n",
       "  ('Granturismo', 'B-GAME'),\n",
       "  ('3', 'I-GAME'),\n",
       "  ('и', '0'),\n",
       "  ('Звезды', 'B-GAME'),\n",
       "  ('Playstation', 'I-GAME'),\n",
       "  ('Битва', '0'),\n",
       "  ('сильнейших', '0'),\n",
       "  ('.', '0'),\n",
       "  ('За', '0'),\n",
       "  ('все', '0'),\n",
       "  ('1500', '0'),\n",
       "  ('руб', '0'),\n",
       "  ('.', '0')],\n",
       " [('Торг', 'B-GAME'), ('обмен', '0')],\n",
       " [('Новый', 'B-GAME')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marked[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показались интересными следующие моменты:\n",
    "\n",
    "1. Сразу бросается в глаза, что сочетание слова, написанного латиницей, и идущего за ним слова (например, Sony PS3), а также просто слов латиницей (hdmi) парсится как игра — возможно, дело в том, что большинство примеров имеют такую же структуру\n",
    "2. Также как игры парсятся сочетания цифр и латиницы — например, 160gb \n",
    "3. В целом сами игры парсятся неплохо и корректно\n",
    "4. Непонятно почему, но «ПС3 Мув» распознались как две игры. То же произошло с «Камерой». Предполагаю, что это может быть связано с тем, что в обучающем файле было несколько предложений, где игры просто перечислялись через запятую\n",
    "5. Слова капсом часто парсятся как игры — вероятно, это тоже связано с наличием в обучающем файле примеров, где названия игр написаны капсом"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
